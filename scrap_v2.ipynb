{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e05556",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msupport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mui\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebDriverWait\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f31fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url for site\n",
    "url = \"https://www.starbucks.com/store-locator?map=36.15032,-86.735135,9z&place=Davidson%20County,%20TN,%20USA\"\n",
    "\n",
    "#defining location of chrome driver in files\n",
    "chrome_driver = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "\n",
    "#creating browser pop up \n",
    "browser = webdriver.Chrome(chrome_driver)\n",
    "#loading website in browser\n",
    "browser.get(url)\n",
    "time.sleep(3)\n",
    "#click agree button for cookies pop up\n",
    "click_agree = browser.find_element(By.CSS_SELECTOR, (\"#truste-consent-button\")).click();\n",
    "#sleep so page loads after agressing to cookies\n",
    "time.sleep(5)\n",
    "\n",
    "html = browser.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab8dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking soup works\n",
    "soup.find('title').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72d18b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#find location names in soup\n",
    "info_loc = soup.findAll('h3', attrs = {'class' : 'sb-heading text-xxs text-bold'})\n",
    "info_loc\n",
    "#create list to store location names\n",
    "#loc_names = {}\n",
    "#looking in info_loc and pulling out location name and putting into list\n",
    "#for info in info_loc:\n",
    "   # loc_names = info.get_text()\n",
    "  #  print(loc_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af946e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#create list to store location names\n",
    "loc_names = [loc.text for loc in info_loc]\n",
    "loc_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7824e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "address_info = soup.findAll('p', attrs = {'data-e2e' : \"address\"})\n",
    "address_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485757c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create list to store location names\n",
    "loc_address = [loc.text for loc in address_info]\n",
    "loc_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc5b783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "starbucks = pd.DataFrame()\n",
    "starbucks['location'] = loc_names\n",
    "starbucks['address'] = loc_address\n",
    "starbucks['address_new'] = starbucks['address'] + ',TN'\n",
    "starbucks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4f7cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks.to_csv('starbucks_locs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0673205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#list comprehension \n",
    "xpaths = \", \".join([f\"//a[@aria-label='Store details for {loc}']//*[name()='svg']\" for loc in loc_names])\n",
    "xpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae9523",
   "metadata": {},
   "outputs": [],
   "source": [
    "xpaths_list = xpaths.split(\", \")\n",
    "type(xpaths_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e10e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xpaths_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#info = browser.find_element(By.XPATH, '//a[@aria-label=\"Store details for Nipper\\'s Corner\"]').click();\n",
    "#time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b182ac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#current_page = browser.page_source\n",
    "#response = requests.get(url2)\n",
    "#soup2 = BeautifulSoup(current_page)\n",
    "#soup2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#container = soup2.find('section', attrs = {'class' : 'pb5 px4 lg-px6'})\n",
    "#container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b88acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for paths in xpaths_list:\n",
    "    #info_button = (f\"browser.find_element(By.XPATH, \\\"{paths}\\\")\")\n",
    "    #info_button.click()\n",
    "    #time.sleep(3)\n",
    "    #scrape page for html  \n",
    "    #names = find_element(By.CSS_SELECTOR, \"h1.sb-heading text-lg text-bold pr7 mb1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df08051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fancy override\n",
    "for index,paths in enumerate(xpaths_list):\n",
    "    if paths.find(\"Nipper\") != -1:\n",
    "        xpaths_list[index] = '//a[@aria-label=\"Store details for Nipper\\'s Corner\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a67602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc_name = []\n",
    "#address = []\n",
    "#zipcode = []\n",
    "big_soup = []\n",
    "\n",
    "for paths in xpaths_list:\n",
    "    try:\n",
    "        info_button = browser.find_element(By.XPATH, paths)\n",
    "        info_button.click();\n",
    "        time.sleep(7)\n",
    "        #get page source \n",
    "        current_page = browser.page_source\n",
    "        #get soup of page\n",
    "        soup2 = BeautifulSoup(current_page)\n",
    "        #find container in soup and place in list\n",
    "        container_soup = soup2.find('section', attrs = {'class' : 'pb5 px4 lg-px6'})\n",
    "        big_soup.append(container_soup)\n",
    "        time.sleep(7)\n",
    "        #click exit \n",
    "        click_exit = browser.find_element(By.XPATH, \"//button[@aria-label='Close']//*[name()='svg']\").click();\n",
    "        time.sleep(7)\n",
    "    except: \n",
    "        print(f'something went wrong at path {paths}') \n",
    "        continue\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a2d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_name = big_soup[0].findAll('h1', attrs = {'class' : \"sb-heading text-lg text-bold pr7 mb1\"})\n",
    "loc_name\n",
    "loc_street = big_soup[0].findAll('span', attrs = {'class' : \"block\"})\n",
    "loc_street[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9edeb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pull out information\n",
    "loc_names = []\n",
    "loc_address = []\n",
    "\n",
    "\n",
    "for container in big_soup:\n",
    "    names = container.findAll('h1', attrs = {'class': \"sb-heading text-lg text-bold pr7 mb1\"})\n",
    "    loc_names.append(names)\n",
    "    address = container.findAll('span', attrs = {'class' : \"block\"})\n",
    "    loc_address.append(address)\n",
    "    \n",
    "loc_address\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf68d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loc_address[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3acdbf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zips = []\n",
    "\n",
    "for lst in loc_address:\n",
    "    if len(lst) == 2:\n",
    "        z = lst[1]\n",
    "        zips.append(z)\n",
    "    elif len(lst) == 3:\n",
    "        z = lst[2]\n",
    "        zips.append(z)\n",
    "\n",
    "zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_zips = pd.read_csv('./data/starbucks_almost.csv')\n",
    "starbucks_zips['zipcodes'] = zips\n",
    "starbucks_zips['zipcodes'] = starbucks_zips['zipcodes'].astype(str)\n",
    "starbucks_zips['zipcodes'] = starbucks_zips['zipcodes'].str.extract('(\\d{5})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d599fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_zips.to_csv('star_zips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc8238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
